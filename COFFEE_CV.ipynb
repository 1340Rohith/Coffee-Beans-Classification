{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d6c3c7-499c-4b18-b989-f49df2ab642d",
   "metadata": {},
   "source": [
    "# Coffee Roast Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a35dd-fd48-4a0f-8d85-37d3852c257f",
   "metadata": {},
   "source": [
    "<h2>Importing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a827ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99163c17-eb0f-49a4-8a22-213da1e97cc2",
   "metadata": {},
   "source": [
    "<h2> Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7da99ee-9a18-4a40-87b3-5a00abe3e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84808f01-d85a-420d-a4a6-96fc3e2d4ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Resize(size=(224,224), antialias=True)\n",
    "])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae3ce4c-3a01-4ec9-9ad3-b78c14f71de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (r'C:\\Users\\rohit\\Desktop\\machine learning\\Datasets\\coffee\\train')\n",
    "dir = os.listdir(path)\n",
    "cat = list(dir)\n",
    "train_fol = torchvision.datasets.ImageFolder(path,transform = transform)\n",
    "train_load = DataLoader(train_fol,\n",
    "                        batch_size=32,\n",
    "                        shuffle=True,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fec4289-eb2e-49b7-a8f9-71f53a1a3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = (r'C:\\Users\\rohit\\Desktop\\machine learning\\Datasets\\coffee\\test')\n",
    "dir1 = os.listdir(path1)\n",
    "cat1 = list(dir1)\n",
    "test_fol = torchvision.datasets.ImageFolder(path1,transform = transform)\n",
    "test_load = DataLoader(test_fol,\n",
    "                        batch_size=32,\n",
    "                        shuffle=True,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabf390d-747c-4a25-ac6a-d3c6c6c5ce63",
   "metadata": {},
   "source": [
    "<h2> Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73cd67bf-894c-4096-9b0a-0a438c84c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mod1(nn.Module):\n",
    "    def __init__(self,input_size:int,hidden_size:int,output_size:int):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = input_size,\n",
    "                      out_channels = hidden_size,\n",
    "                      kernel_size = (3,3),\n",
    "                      stride=1,\n",
    "                      padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = (2,2))\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = hidden_size,\n",
    "                      out_channels = hidden_size,\n",
    "                      kernel_size = (3,3),\n",
    "                      stride=1,\n",
    "                      padding=\"same\"),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size = (2,2))\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = hidden_size,\n",
    "                      out_channels = hidden_size,\n",
    "                      kernel_size = (3,3),\n",
    "                      stride=1,\n",
    "                      padding=\"same\"),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size = (2,2))\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = hidden_size,\n",
    "                      out_channels = hidden_size,\n",
    "                      kernel_size = (3,3),\n",
    "                      stride=1,\n",
    "                      padding=\"same\"),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size = (2,2))\n",
    "        )\n",
    "        self.conn = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features = hidden_size*14*14,\n",
    "                      out_features = hidden_size*14*14),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features = hidden_size*14*14,\n",
    "                      out_features = hidden_size*14*14),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features = hidden_size*14*14,\n",
    "                      out_features = output_size),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.conn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987a860e-def3-4b13-a7cd-8053a6bbb990",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "lr = 0.0006\n",
    "model = mod1(3,15,4).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = lr)\n",
    "loss = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd28b88-b3d8-45cf-add1-82eb10e9c05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651b1698cc7f4afda2256a5fc329ac78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COST PER EPOCH : 1.3925727605819702   TEST LOSS : 1.3862990140914917  TEST ACCURACY : 24.51923076923077\n",
      "COST PER EPOCH : 1.386260986328125   TEST LOSS : 1.3941317796707153  TEST ACCURACY : 25.0\n",
      "COST PER EPOCH : 1.38828706741333   TEST LOSS : 1.3862981796264648  TEST ACCURACY : 24.51923076923077\n",
      "COST PER EPOCH : 1.3863240480422974   TEST LOSS : 1.3862683773040771  TEST ACCURACY : 25.721153846153847\n",
      "COST PER EPOCH : 1.386304497718811   TEST LOSS : 1.38633131980896  TEST ACCURACY : 24.278846153846153\n",
      "COST PER EPOCH : 1.3862991333007812   TEST LOSS : 1.3861361742019653  TEST ACCURACY : 30.76923076923077\n",
      "COST PER EPOCH : 1.4028819799423218   TEST LOSS : 1.3838791847229004  TEST ACCURACY : 29.08653846153846\n",
      "COST PER EPOCH : 1.3408883810043335   TEST LOSS : 1.0898807048797607  TEST ACCURACY : 51.44230769230769\n",
      "COST PER EPOCH : 0.8362435102462769   TEST LOSS : 0.6699026226997375  TEST ACCURACY : 62.5\n",
      "COST PER EPOCH : 0.5274962782859802   TEST LOSS : 0.34171319007873535  TEST ACCURACY : 87.98076923076923\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(epoch)):\n",
    "    train_loss = 0\n",
    "    test_accuracy =0 \n",
    "    test_loss = 0\n",
    "\n",
    "    for batch,(x,y) in enumerate(train_load):\n",
    "        model.train()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        logit = model(x)\n",
    "        cost = loss(logit,y)\n",
    "        train_loss +=cost\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch,(x,y) in enumerate(test_load):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logit = model(x)\n",
    "            cost = loss(logit,y)\n",
    "            test_loss += cost\n",
    "            acc = accuracy_score(y.cpu(),logit.argmax(dim=1).cpu())\n",
    "            acc = acc*100\n",
    "            test_accuracy += acc\n",
    "        \n",
    "        \n",
    "        train_loss = train_loss/len(train_load)\n",
    "        test_loss = test_loss/len(test_load)\n",
    "        test_accuracy = test_accuracy/len(test_load)\n",
    "        print(f\"COST PER EPOCH : {train_loss}   TEST LOSS : {test_loss}  TEST ACCURACY : {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfaa99c-c50f-4a9a-9a98-4862f0a642ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
